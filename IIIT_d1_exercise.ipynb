{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IIIT d1 exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSCOOuKoLgOOxyxKkrm6d8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mssuhas/IIIT-training/blob/main/IIIT_d1_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T84AWIpSDNCy"
      },
      "source": [
        "#Import necessary libraries \n",
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0nRrg_oDaaF",
        "outputId": "bf663123-5f12-4b8d-e649-89d719ab0609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path=\"/content/winequality-red.csv\" \n",
        "wine_dataset_frame = pd.read_csv(path, header=None, delimiter=';') \n",
        "print(\"Wine dataframe looks like \\n\", wine_dataset_frame) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wine dataframe looks like \n",
            "                  0                 1            2   ...         9        10       11\n",
            "0     fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
            "1               7.4               0.7            0  ...       0.56      9.4        5\n",
            "2               7.8              0.88            0  ...       0.68      9.8        5\n",
            "3               7.8              0.76         0.04  ...       0.65      9.8        5\n",
            "4              11.2              0.28         0.56  ...       0.58      9.8        6\n",
            "...             ...               ...          ...  ...        ...      ...      ...\n",
            "1595            6.2               0.6         0.08  ...       0.58     10.5        5\n",
            "1596            5.9              0.55          0.1  ...       0.76     11.2        6\n",
            "1597            6.3              0.51         0.13  ...       0.75       11        6\n",
            "1598            5.9             0.645         0.12  ...       0.71     10.2        5\n",
            "1599              6              0.31         0.47  ...       0.66       11        6\n",
            "\n",
            "[1600 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye3wIQbgEcKF",
        "outputId": "86a77330-a32d-4199-a09b-c8a2db3345fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Getting feature values and targets of the dataset \n",
        "wine_dataset = wine_dataset_frame.to_numpy() \n",
        "print(\"np.shape(wine_databaseset:): \",wine_dataset.shape) \n",
        "wine_dataset_features = wine_dataset[1:1599,0:11] \n",
        "print(\"Wine dataset features values are: \\n\", wine_dataset_features,\"\\n\") \n",
        "print(\"Shape of wine dataset features is: \", np.shape(wine_dataset_features),\"\\n\") \n",
        "wine_dataset_target = wine_dataset[1:1599:,11] \n",
        "print(\"Wine dataset target values are: \\n\", wine_dataset_target,\"\\n\") \n",
        "print(\"Shape of wine dataset target values is: \", np.shape(wine_dataset_target),\"\\n\") \n",
        " \n",
        "#Dividing the Wine Quality dataset into training and testing dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split(wine_dataset_features, wine_dataset_target, test_size=0.50 , random_state=42) \n",
        " \n",
        "#Displaying the training dataset \n",
        "print(\"Training data is: \\n\", x_train,\"\\n\") \n",
        "print(\"Shape of training data is: \",np.shape(x_train),\"\\n\") \n",
        "print(\"Training labels are: \\n\", y_train, \"\\n\") \n",
        "print(\"Shape of training labels is: \",np.shape(y_train), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "np.shape(wine_databaseset:):  (1600, 12)\n",
            "Wine dataset features values are: \n",
            " [['7.4' '0.7' '0' ... '3.51' '0.56' '9.4']\n",
            " ['7.8' '0.88' '0' ... '3.2' '0.68' '9.8']\n",
            " ['7.8' '0.76' '0.04' ... '3.26' '0.65' '9.8']\n",
            " ...\n",
            " ['5.9' '0.55' '0.1' ... '3.52' '0.76' '11.2']\n",
            " ['6.3' '0.51' '0.13' ... '3.42' '0.75' '11']\n",
            " ['5.9' '0.645' '0.12' ... '3.57' '0.71' '10.2']] \n",
            "\n",
            "Shape of wine dataset features is:  (1598, 11) \n",
            "\n",
            "Wine dataset target values are: \n",
            " ['5' '5' '5' ... '6' '6' '5'] \n",
            "\n",
            "Shape of wine dataset target values is:  (1598,) \n",
            "\n",
            "Training data is: \n",
            " [['11.6' '0.41' '0.54' ... '3.02' '0.76' '9.9']\n",
            " ['8.6' '0.52' '0.38' ... '3.2' '0.52' '9.4']\n",
            " ['7.8' '0.56' '0.19' ... '3.19' '0.93' '9.5']\n",
            " ...\n",
            " ['7.2' '0.62' '0.06' ... '3.51' '0.54' '9.5']\n",
            " ['7.9' '0.2' '0.35' ... '3.32' '0.8' '11.9']\n",
            " ['5.8' '0.29' '0.26' ... '3.39' '0.54' '13.5']] \n",
            "\n",
            "Shape of training data is:  (799, 11) \n",
            "\n",
            "Training labels are: \n",
            " ['7' '5' '5' '7' '6' '6' '5' '6' '5' '6' '5' '5' '5' '6' '5' '7' '7' '5'\n",
            " '5' '5' '5' '5' '5' '5' '4' '6' '3' '5' '5' '6' '6' '5' '6' '7' '5' '5'\n",
            " '7' '6' '6' '6' '6' '7' '6' '6' '5' '5' '7' '8' '5' '5' '6' '3' '5' '6'\n",
            " '5' '6' '6' '7' '8' '6' '5' '6' '5' '5' '6' '6' '6' '5' '4' '6' '6' '6'\n",
            " '6' '6' '6' '5' '5' '8' '6' '5' '6' '6' '6' '6' '7' '5' '5' '6' '6' '6'\n",
            " '6' '6' '6' '6' '5' '5' '6' '7' '6' '4' '5' '5' '5' '6' '5' '6' '6' '5'\n",
            " '6' '7' '6' '5' '7' '7' '5' '5' '6' '6' '6' '5' '5' '5' '5' '6' '6' '5'\n",
            " '6' '5' '5' '7' '5' '6' '4' '5' '6' '5' '6' '5' '7' '5' '4' '5' '6' '5'\n",
            " '6' '6' '6' '5' '6' '5' '6' '7' '6' '5' '5' '5' '6' '5' '5' '6' '6' '6'\n",
            " '4' '6' '7' '5' '6' '7' '6' '6' '5' '7' '5' '5' '5' '5' '6' '6' '7' '6'\n",
            " '6' '5' '7' '5' '6' '5' '5' '6' '5' '7' '6' '5' '6' '8' '5' '6' '6' '6'\n",
            " '6' '5' '6' '6' '5' '4' '6' '6' '5' '4' '5' '5' '5' '5' '6' '7' '5' '5'\n",
            " '5' '6' '5' '6' '5' '7' '5' '6' '5' '6' '7' '6' '8' '6' '5' '6' '5' '6'\n",
            " '4' '5' '5' '7' '7' '5' '5' '5' '6' '6' '5' '5' '5' '7' '5' '6' '7' '7'\n",
            " '5' '5' '5' '7' '6' '5' '6' '5' '5' '6' '6' '5' '7' '6' '7' '6' '5' '5'\n",
            " '5' '5' '5' '5' '5' '7' '7' '5' '6' '5' '6' '5' '5' '5' '4' '6' '5' '8'\n",
            " '6' '6' '6' '3' '5' '5' '6' '6' '5' '5' '5' '5' '5' '5' '7' '5' '5' '5'\n",
            " '5' '6' '5' '6' '6' '5' '5' '6' '5' '5' '8' '5' '5' '5' '7' '3' '4' '5'\n",
            " '5' '5' '6' '6' '4' '5' '7' '6' '6' '5' '6' '6' '7' '5' '6' '5' '5' '5'\n",
            " '5' '5' '6' '5' '5' '5' '6' '6' '6' '6' '5' '7' '7' '6' '6' '6' '7' '5'\n",
            " '5' '5' '6' '5' '5' '4' '5' '6' '6' '6' '5' '5' '6' '4' '6' '6' '7' '6'\n",
            " '6' '6' '7' '4' '6' '5' '6' '5' '7' '6' '5' '6' '5' '6' '5' '5' '5' '4'\n",
            " '6' '5' '5' '7' '5' '5' '6' '6' '7' '7' '5' '7' '5' '5' '5' '5' '6' '6'\n",
            " '6' '5' '6' '6' '4' '6' '5' '5' '6' '6' '5' '6' '7' '6' '5' '6' '7' '5'\n",
            " '7' '7' '5' '6' '5' '6' '6' '6' '6' '5' '6' '5' '5' '6' '5' '5' '6' '5'\n",
            " '5' '5' '6' '4' '6' '6' '5' '6' '6' '5' '6' '7' '5' '6' '6' '5' '5' '6'\n",
            " '3' '5' '5' '5' '5' '6' '7' '6' '6' '6' '6' '6' '5' '6' '5' '5' '7' '7'\n",
            " '6' '5' '6' '5' '5' '7' '6' '6' '5' '6' '6' '5' '7' '6' '5' '6' '6' '5'\n",
            " '6' '5' '5' '5' '6' '5' '7' '6' '6' '7' '5' '6' '7' '6' '6' '5' '5' '7'\n",
            " '6' '6' '5' '4' '6' '8' '5' '5' '6' '5' '7' '6' '6' '6' '6' '5' '6' '7'\n",
            " '5' '5' '6' '6' '5' '6' '5' '6' '6' '6' '5' '5' '5' '6' '5' '7' '5' '6'\n",
            " '5' '6' '6' '6' '4' '5' '5' '5' '7' '6' '6' '5' '5' '5' '6' '5' '7' '6'\n",
            " '6' '5' '5' '5' '5' '5' '5' '6' '6' '6' '5' '7' '6' '5' '5' '5' '5' '5'\n",
            " '5' '7' '6' '6' '5' '6' '6' '5' '5' '6' '6' '6' '7' '6' '7' '6' '5' '6'\n",
            " '7' '5' '6' '5' '5' '7' '6' '6' '5' '6' '5' '5' '5' '5' '7' '5' '6' '6'\n",
            " '5' '6' '6' '5' '5' '7' '5' '6' '6' '5' '5' '6' '6' '6' '6' '6' '5' '5'\n",
            " '5' '7' '7' '5' '6' '6' '6' '5' '7' '5' '6' '5' '6' '6' '5' '5' '5' '6'\n",
            " '6' '7' '5' '7' '7' '5' '7' '6' '5' '5' '6' '7' '6' '7' '6' '6' '5' '7'\n",
            " '7' '4' '5' '6' '6' '5' '5' '6' '6' '7' '6' '5' '5' '5' '5' '6' '6' '5'\n",
            " '5' '5' '7' '6' '5' '8' '5' '5' '6' '6' '5' '4' '6' '6' '6' '5' '6' '5'\n",
            " '5' '6' '6' '6' '6' '7' '5' '5' '6' '7' '3' '5' '6' '6' '4' '6' '6' '4'\n",
            " '6' '6' '5' '6' '4' '6' '6' '5' '7' '6' '5' '6' '6' '6' '6' '6' '5' '5'\n",
            " '5' '6' '5' '5' '6' '6' '5' '6' '6' '6' '5' '5' '5' '5' '3' '5' '6' '5'\n",
            " '6' '6' '7' '5' '6' '6' '5' '6' '5' '5' '6' '5' '5' '4' '6' '4' '6' '6'\n",
            " '6' '5' '6' '6' '5' '7' '6'] \n",
            "\n",
            "Shape of training labels is:  (799,) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU0uMaoREeFu",
        "outputId": "8f86728d-2d36-437a-edff-334ff74dde6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Displaying the test dataset \n",
        "print(\"Testing data is: \\n\", x_test,\"\\n\") \n",
        "print(\"Shape of testing data is: \",np.shape(x_test),\"\\n\") \n",
        "print(\"Testing labels are: \\n\", y_test, \"\\n\") \n",
        "print(\"Shape of testing labels is: \",np.shape(y_test), \"\\n\") \n",
        " \n",
        "#Building the Ridge Regression model \n",
        "from sklearn.linear_model import Ridge \n",
        "ridge_regression_classifier = Ridge(fit_intercept=True, normalize=True) \n",
        "print(ridge_regression_classifier) \n",
        " \n",
        "#Building the Linear Regression Model \n",
        "from sklearn.linear_model import LinearRegression \n",
        "linear_regression_classifier = LinearRegression(fit_intercept=True, normalize=True) \n",
        "print(linear_regression_classifier) \n",
        " \n",
        "#training the Ridge Regressor Model \n",
        "ridge_regression_classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data is: \n",
            " [['7.7' '0.56' '0.08' ... '3.24' '0.66' '9.6']\n",
            " ['7.8' '0.5' '0.17' ... '3.39' '0.48' '9.5']\n",
            " ['10.7' '0.67' '0.22' ... '3.28' '0.98' '9.9']\n",
            " ...\n",
            " ['7.4' '0.61' '0.01' ... '3.48' '0.65' '9.8']\n",
            " ['6.9' '0.51' '0.23' ... '3.4' '0.84' '11.2']\n",
            " ['7.2' '0.73' '0.02' ... '3.44' '0.52' '9.3']] \n",
            "\n",
            "Shape of testing data is:  (799, 11) \n",
            "\n",
            "Testing labels are: \n",
            " ['6' '5' '6' '5' '6' '5' '5' '5' '5' '5' '7' '6' '6' '5' '6' '7' '5' '7'\n",
            " '8' '5' '5' '6' '5' '5' '6' '6' '7' '6' '5' '6' '5' '5' '6' '5' '6' '5'\n",
            " '7' '6' '4' '6' '5' '5' '7' '5' '5' '6' '7' '6' '5' '6' '5' '5' '5' '7'\n",
            " '6' '6' '6' '5' '6' '5' '5' '7' '5' '6' '6' '5' '6' '5' '5' '5' '6' '4'\n",
            " '6' '6' '6' '5' '6' '5' '6' '5' '5' '6' '5' '6' '6' '7' '5' '6' '7' '6'\n",
            " '7' '6' '5' '5' '5' '6' '5' '5' '5' '6' '7' '6' '5' '7' '7' '7' '6' '5'\n",
            " '6' '5' '8' '5' '6' '5' '6' '7' '6' '6' '5' '6' '6' '6' '6' '6' '6' '6'\n",
            " '5' '6' '5' '6' '6' '5' '5' '5' '6' '5' '5' '5' '5' '6' '7' '6' '5' '5'\n",
            " '5' '5' '6' '6' '6' '5' '7' '7' '6' '5' '6' '4' '5' '6' '6' '6' '7' '5'\n",
            " '7' '5' '6' '6' '6' '6' '6' '5' '6' '5' '6' '6' '7' '6' '6' '5' '5' '6'\n",
            " '4' '6' '5' '7' '5' '5' '5' '5' '7' '6' '5' '6' '6' '7' '6' '6' '6' '6'\n",
            " '5' '7' '5' '6' '6' '5' '7' '6' '5' '5' '6' '7' '7' '5' '5' '6' '6' '7'\n",
            " '6' '5' '5' '6' '6' '6' '6' '7' '4' '5' '5' '7' '5' '6' '5' '5' '6' '6'\n",
            " '5' '7' '5' '6' '6' '6' '5' '4' '5' '7' '6' '7' '5' '6' '6' '5' '5' '6'\n",
            " '5' '6' '4' '5' '7' '6' '5' '8' '6' '5' '5' '6' '7' '5' '6' '5' '6' '6'\n",
            " '4' '6' '5' '6' '5' '5' '5' '6' '6' '6' '7' '5' '6' '6' '6' '7' '5' '6'\n",
            " '4' '6' '6' '8' '6' '4' '5' '6' '5' '7' '6' '6' '5' '5' '7' '6' '6' '5'\n",
            " '6' '6' '6' '7' '6' '6' '6' '6' '5' '6' '6' '5' '6' '4' '6' '6' '6' '5'\n",
            " '5' '5' '5' '8' '6' '6' '6' '7' '6' '6' '6' '5' '5' '7' '5' '5' '6' '7'\n",
            " '6' '5' '6' '5' '6' '5' '6' '5' '5' '5' '5' '6' '6' '6' '5' '5' '4' '5'\n",
            " '4' '5' '6' '6' '5' '7' '6' '7' '5' '6' '5' '5' '6' '6' '6' '6' '6' '6'\n",
            " '5' '6' '5' '5' '6' '6' '6' '7' '5' '5' '6' '6' '6' '5' '5' '5' '7' '5'\n",
            " '5' '6' '5' '7' '5' '5' '7' '5' '6' '7' '7' '6' '6' '6' '6' '6' '7' '6'\n",
            " '5' '7' '6' '6' '6' '5' '5' '5' '6' '5' '6' '5' '5' '5' '7' '6' '7' '6'\n",
            " '4' '5' '7' '5' '5' '5' '6' '6' '6' '6' '6' '5' '6' '5' '6' '5' '6' '6'\n",
            " '7' '6' '6' '5' '6' '6' '7' '5' '7' '5' '5' '6' '5' '5' '6' '5' '6' '5'\n",
            " '5' '6' '6' '5' '6' '5' '5' '4' '8' '6' '7' '4' '7' '5' '5' '6' '6' '5'\n",
            " '7' '5' '5' '5' '6' '5' '3' '7' '6' '5' '7' '5' '5' '5' '5' '6' '6' '5'\n",
            " '5' '5' '6' '6' '7' '6' '6' '7' '5' '6' '5' '8' '6' '6' '5' '5' '6' '5'\n",
            " '7' '4' '7' '7' '5' '5' '6' '6' '5' '7' '5' '6' '6' '5' '5' '5' '5' '6'\n",
            " '5' '5' '6' '5' '5' '5' '5' '5' '6' '6' '6' '5' '6' '5' '5' '6' '5' '6'\n",
            " '6' '6' '5' '6' '6' '6' '5' '5' '5' '5' '5' '7' '6' '5' '6' '6' '5' '5'\n",
            " '5' '8' '5' '5' '5' '6' '5' '6' '5' '7' '6' '5' '6' '5' '6' '5' '5' '5'\n",
            " '4' '5' '6' '5' '5' '7' '5' '5' '7' '5' '5' '6' '6' '5' '5' '6' '5' '5'\n",
            " '5' '7' '7' '5' '7' '6' '5' '6' '5' '5' '5' '6' '5' '7' '5' '6' '4' '5'\n",
            " '6' '5' '3' '5' '7' '5' '6' '5' '5' '6' '6' '5' '5' '5' '4' '5' '4' '6'\n",
            " '7' '5' '7' '5' '6' '4' '5' '7' '4' '7' '6' '6' '6' '6' '5' '6' '5' '5'\n",
            " '5' '6' '5' '5' '5' '6' '5' '6' '5' '5' '7' '6' '7' '5' '6' '5' '6' '5'\n",
            " '6' '6' '6' '5' '7' '6' '5' '7' '7' '8' '5' '5' '5' '7' '7' '6' '4' '5'\n",
            " '5' '6' '6' '6' '6' '5' '5' '6' '6' '6' '5' '7' '5' '7' '5' '5' '5' '5'\n",
            " '6' '6' '6' '7' '6' '7' '6' '7' '5' '5' '5' '5' '5' '5' '6' '5' '5' '5'\n",
            " '7' '6' '5' '5' '5' '6' '5' '4' '6' '7' '6' '5' '5' '7' '5' '7' '5' '5'\n",
            " '6' '5' '5' '5' '6' '5' '5' '5' '5' '5' '7' '5' '6' '6' '5' '4' '6' '5'\n",
            " '6' '5' '5' '3' '6' '6' '6' '5' '6' '5' '5' '6' '5' '7' '5' '6' '6' '5'\n",
            " '6' '6' '6' '5' '5' '6' '5'] \n",
            "\n",
            "Shape of testing labels is:  (799,) \n",
            "\n",
            "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, normalize=True,\n",
            "      random_state=None, solver='auto', tol=0.001)\n",
            "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, normalize=True,\n",
              "      random_state=None, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSw5LSYLErQM",
        "outputId": "eac4a35c-c550-42cf-c86f-399b5d08bfee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training the Ridge Regressor Model \n",
        "linear_regression_classifier.fit(x_train, y_train) \n",
        " \n",
        "#printing the Ridge regressor arguments \n",
        "print(\"Ridge regression coefficients = \",ridge_regression_classifier.coef_) \n",
        "print(\"Ridge regression intercept = \",ridge_regression_classifier.intercept_) \n",
        " \n",
        "#printing the Linear regressor arguments \n",
        "print(\"Linear regression coefficients = \",linear_regression_classifier.coef_) \n",
        "print(\"Linear regression intercept = \",linear_regression_classifier.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ridge regression coefficients =  [ 1.80255380e-02 -6.85415317e-01  1.91270724e-01  7.19720395e-04\n",
            " -1.03148392e+00  6.99899071e-04 -1.78306363e-03 -2.64407282e+01\n",
            " -3.08962396e-02  3.85324164e-01  1.43761153e-01]\n",
            "Ridge regression intercept =  30.65031790077454\n",
            "Linear regression coefficients =  [-8.23240983e-03 -1.28038663e+00 -1.59536182e-01 -2.10404896e-02\n",
            " -1.83320833e+00  6.25479173e-03 -3.64007524e-03  1.86541337e+01\n",
            " -4.07522220e-01  6.41609060e-01  3.01380588e-01]\n",
            "Linear regression intercept =  -14.114938748947948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZIMh0tkEzEB",
        "outputId": "18294ea2-4202-4a4d-d634-c48aa9f04d1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#making the pridictions on the testing dataset of Ridge regression \n",
        "ridge_regression_predictions = ridge_regression_classifier.predict(x_test) \n",
        "print(\"The predictions of the Ridge regressor are: \\n\", ridge_regression_predictions,\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predictions of the Ridge regressor are: \n",
            " [5.40283853 5.34110373 5.51709998 5.51388368 5.72256427 5.45251117\n",
            " 5.79710072 5.32508427 5.75306588 5.86953013 5.96713743 5.68383223\n",
            " 5.68169467 5.46211427 5.58884478 6.23037395 5.32431809 5.62540618\n",
            " 6.20826777 5.36886531 5.46222756 5.37528224 5.55159161 5.37607894\n",
            " 5.42898184 5.51342891 6.01669794 5.47679984 5.26534653 5.98343909\n",
            " 5.21428262 5.50228001 5.75682554 5.51260271 5.46164815 5.29292703\n",
            " 6.02149749 6.14644856 5.66205201 6.06087341 5.60507228 5.39208348\n",
            " 5.97359199 5.31339225 5.7891662  5.64972977 6.11992548 5.64858916\n",
            " 5.33682726 5.55362474 5.19010412 5.29969513 5.57083378 6.01418206\n",
            " 5.2915338  5.25734575 5.85272139 5.38519399 5.45867229 5.43320952\n",
            " 5.56460723 5.85051958 5.50133495 5.53738224 6.17650104 5.60993857\n",
            " 6.17192617 5.35846125 5.55195182 5.46293288 6.16959607 5.06983733\n",
            " 5.76898742 5.75735803 5.97846923 5.41406333 5.51418591 5.80205487\n",
            " 5.92070485 5.50894377 5.47980737 5.36171123 5.47077488 5.66923728\n",
            " 5.59832923 6.03140587 5.49828854 5.75726753 6.04284295 5.63468545\n",
            " 5.82543815 5.66707779 5.64684477 5.79262487 5.49586907 5.76573064\n",
            " 5.32634815 5.38031235 5.26924277 5.51971887 5.68725341 5.71822832\n",
            " 5.7155488  5.63235789 5.94201233 5.97119777 5.73051573 5.41295171\n",
            " 5.88621304 5.36941269 6.32376329 5.36480896 5.88514408 5.13133397\n",
            " 5.43491265 5.87123115 5.95307905 5.50757663 5.346259   5.67106192\n",
            " 6.01002109 5.2764409  5.6715281  5.42802937 5.4944584  5.3756917\n",
            " 6.04990298 5.61937022 5.7381236  6.09740106 5.76898742 5.44078241\n",
            " 5.25856879 6.14880977 5.55362474 5.26070386 5.2272529  5.49931343\n",
            " 5.21765845 5.59539305 5.85872364 5.87762193 5.44343673 5.51486567\n",
            " 5.78270035 5.36883947 5.77823747 5.43725576 5.87362818 5.28635185\n",
            " 6.09190023 5.98579715 5.26891707 5.65070194 5.76898742 5.39701371\n",
            " 5.3732958  5.87611114 5.81260557 5.81846907 6.09116629 5.69294525\n",
            " 5.90646855 5.24048399 5.78904633 5.65973139 5.04922444 5.41035816\n",
            " 5.14827928 5.26715334 6.00372458 5.41301526 5.25096346 5.47520981\n",
            " 5.81401936 5.72000966 5.89254812 5.54835178 5.59480561 5.50428888\n",
            " 5.08674767 6.13655381 5.56554385 6.2269651  5.36942298 6.01899782\n",
            " 5.94501672 5.8585658  6.34027346 5.47520981 5.43414273 5.8674741\n",
            " 5.60963337 6.16729292 5.71874948 5.72256427 5.63050108 5.52987192\n",
            " 5.51207295 5.97119777 5.45363638 5.54833069 5.65617673 5.2767153\n",
            " 6.20993543 5.97234839 5.17136821 5.74475418 5.74114376 5.81534012\n",
            " 5.83366713 5.20068703 5.39040418 6.10733101 6.19280152 5.68089127\n",
            " 5.39805586 5.38164071 5.32252109 5.46872454 5.26745589 6.04986741\n",
            " 5.58611152 5.85561052 5.32366669 5.09729469 5.3859827  6.15901344\n",
            " 5.51202984 5.88671373 5.53796256 5.20148328 6.11479893 5.87208253\n",
            " 5.71901906 5.97119777 5.46211427 5.59832923 5.12422962 5.28679668\n",
            " 5.73542704 5.28018624 5.48407682 5.97084266 5.42165925 5.55947379\n",
            " 5.76678324 5.50229033 6.29823741 5.10718337 5.70081143 5.67227838\n",
            " 5.35918047 5.46746417 5.33829426 5.37211574 5.99116535 5.72335526\n",
            " 5.66753588 6.26273543 5.7841225  5.41330116 5.54835178 6.1869758\n",
            " 5.74662197 5.25854769 5.2446509  5.23923069 5.85002801 6.08366843\n",
            " 5.7248129  5.61859787 5.17363499 5.34326103 5.47009242 5.66650081\n",
            " 5.63143479 5.66129164 5.96341746 5.37925223 6.17654509 5.25688427\n",
            " 5.67769135 5.56531723 5.70849781 5.63835947 5.20759229 5.87762193\n",
            " 5.1405244  5.36323642 5.90021358 6.20970096 5.70028807 5.368955\n",
            " 5.19185988 6.08668714 5.28590853 6.04447474 5.99604381 6.22841982\n",
            " 5.54361323 5.39410216 6.02547456 5.47105281 5.42798794 5.50830316\n",
            " 5.67344686 5.76466675 6.26523803 6.2840302  5.60335938 5.58185337\n",
            " 5.61211588 5.67480403 5.51260271 5.60335401 5.91920346 5.43147146\n",
            " 6.02061053 5.30925378 5.5778525  5.98955124 5.73095837 5.33979453\n",
            " 5.05508808 5.62052249 5.16947953 5.9609649  5.25734575 5.98343909\n",
            " 5.91830884 6.2840302  5.28389657 5.25006805 5.67843058 5.08511892\n",
            " 5.67683778 6.06478752 5.52622853 5.44409856 6.02948273 6.14814415\n",
            " 6.28220673 5.44417852 5.76610526 5.19296675 5.97846923 5.35924194\n",
            " 5.54069131 5.3559421  5.44728952 5.79610197 5.61071835 5.14827928\n",
            " 5.54288436 5.64010618 5.32856345 5.27288248 5.38951    5.63513641\n",
            " 5.70813789 5.51025832 6.00591237 5.60335938 5.42465169 5.76790878\n",
            " 5.74368364 6.17087979 5.34436455 5.71806303 5.50526256 5.32252109\n",
            " 5.82871111 5.66796483 5.51457106 6.06087341 5.49344304 6.05974525\n",
            " 5.46014836 5.50402525 5.29012491 5.97169469 6.13631305 5.48118084\n",
            " 6.02858283 5.77917569 5.95469771 5.31628397 5.61493363 5.63180543\n",
            " 5.65709865 5.60321212 5.21832846 5.14876169 5.93322168 5.46211427\n",
            " 5.9871091  5.46164815 5.37521956 6.00522554 5.4608144  5.31463809\n",
            " 5.71705149 5.31936152 5.45825293 5.70645451 6.02429687 5.96462098\n",
            " 5.89984278 5.60335401 5.45262431 6.0666761  5.98751226 5.6602258\n",
            " 5.76546263 5.83670998 5.53735777 6.23531214 5.57713665 6.08098183\n",
            " 5.72664209 5.623835   6.16393972 5.39687791 5.69764523 5.88171213\n",
            " 5.51429451 5.52936562 5.63235789 5.44953213 6.35231372 5.62472592\n",
            " 5.27166406 5.29382186 6.12920661 5.36627817 5.48810342 5.51970391\n",
            " 5.18753254 6.3335564  5.43387481 5.90311014 6.1885511  5.40068576\n",
            " 5.5197529  5.21003395 5.35351602 5.69930558 5.60878691 5.38930871\n",
            " 5.94103764 5.70731551 5.73186347 5.30611991 5.63930354 6.04548722\n",
            " 6.24718153 5.30203249 5.88345374 5.28020633 5.21456936 5.35918262\n",
            " 5.49933817 5.55619738 5.90488903 5.59406136 5.3820922  5.48667948\n",
            " 5.79259206 6.20674574 6.13363422 5.77853116 5.65327394 5.77853116\n",
            " 5.41809668 5.30694057 5.97712323 5.72256427 5.96713743 5.55884511\n",
            " 6.0319267  5.88672086 5.65084005 5.61853802 5.99015283 5.39765723\n",
            " 5.77229613 5.99124845 5.46211427 5.40520271 6.03909767 5.65070194\n",
            " 5.10116743 5.8262164  5.67004986 5.18151417 5.85872364 5.42282866\n",
            " 5.17511365 5.34462268 5.23986903 5.55398535 5.41529249 5.61071835\n",
            " 5.40570387 5.34069734 5.47356638 5.60335938 6.10810563 5.94735228\n",
            " 5.72451104 6.10810563 5.34187444 5.889695   5.2961829  6.20548402\n",
            " 5.8317067  5.36263992 5.47077488 5.28529168 5.79016653 5.38110219\n",
            " 5.88497509 5.89751033 6.35499981 6.21627454 5.0861013  5.24647432\n",
            " 5.80676087 5.77881598 5.25854769 6.02920768 5.36886531 5.56339471\n",
            " 5.54310434 5.26291557 5.58232118 5.23809208 5.63712606 6.09838814\n",
            " 5.39214309 5.28170746 5.82483925 5.36079448 5.71898241 5.7061483\n",
            " 5.22971185 5.56943586 5.43526482 5.26758238 5.62907335 5.71148519\n",
            " 5.12422962 5.21801269 5.49480557 5.68900717 5.2710332  5.54989667\n",
            " 5.86490949 5.37152222 5.28048021 5.36323642 5.64033699 5.46083308\n",
            " 5.40247941 5.85296589 5.89314828 5.59786292 5.30555759 6.10084148\n",
            " 6.17113053 5.34443332 6.00234025 5.58774314 5.82256244 5.62342\n",
            " 5.25524149 5.80501686 5.45596271 5.4994602  5.38307338 5.27856411\n",
            " 5.51141775 5.75481484 5.30614543 6.04272455 5.90228748 5.00251911\n",
            " 5.57856469 5.11604632 5.68508143 5.52838995 5.28945627 5.68311244\n",
            " 5.34484435 5.9375995  5.86134696 5.8545502  5.2934695  6.20974692\n",
            " 5.17174464 5.21451609 5.67728372 6.13184284 5.6613424  5.6483349\n",
            " 5.89662593 5.01768863 5.40980638 5.56518985 5.83716278 5.95321723\n",
            " 4.79997446 5.97084266 6.00078568 5.61450956 5.72652499 6.06248313\n",
            " 5.44556346 6.12983057 5.44141518 5.86953013 5.01592987 5.81843238\n",
            " 5.34654697 5.6864464  5.35860516 5.55398535 5.324855   5.368057\n",
            " 5.52671671 5.60889977 5.12639648 5.37982646 5.57612204 5.31533207\n",
            " 5.43835229 5.33181276 5.41891833 5.50362801 5.79245054 5.31161966\n",
            " 5.60996439 5.48601895 5.49659838 5.25128883 5.63094835 5.39805586\n",
            " 6.15179145 5.33293688 6.16834807 5.27332972 5.33406648 5.50143462\n",
            " 5.49335218 5.97858746 5.46121526 6.1258061  5.33840115 5.81049206\n",
            " 5.75682554 5.74318833 5.27467922 6.40124675 5.32072921 5.26917509\n",
            " 5.46651847 5.98462357 5.43320952 5.66738177 5.47428486 5.30882479\n",
            " 5.36883947 6.1487722  5.34258544 5.2641207  6.05676235 5.82706438\n",
            " 6.39699771 5.43807731 5.47592634 5.51643928 5.88801049 5.46680427\n",
            " 5.46422078 5.44868126 5.95570791 5.78616609 5.69007769 5.35983417\n",
            " 5.77984712 6.28324435 5.8392847  6.03763758 5.33682726 5.38470156\n",
            " 5.26317397 6.20495488 6.13992564 5.56660222 5.29164229 5.45726066\n",
            " 5.30109515 5.91864511 5.82706438 5.54615029 5.58201357 5.44969708\n",
            " 5.24549067 5.73159802 5.55987785 5.34880292 5.37945151 6.24067435\n",
            " 5.41406333 6.00728523 5.52778582 5.5279358  5.52904394 5.75928516\n",
            " 5.56949906 5.40428236 5.1453384  5.99116535 5.42798794 6.15974837\n",
            " 5.77011103 6.15110239 5.33752721 5.77909083 5.59886201 5.45217347\n",
            " 5.29581642 5.30932838 5.3492378  5.89747084 5.44710509 5.41160574\n",
            " 5.55947379 5.70808826 5.60611661 5.76546263 5.63860295 5.94162003\n",
            " 5.48542446 5.35452157 5.38972189 5.27066251 5.4128378  5.38307338\n",
            " 5.06015715 6.22371906 5.29146179 6.01388175 5.63619963 5.54016934\n",
            " 6.18549162 5.89543155 5.66489396 5.42630296 5.29407414 5.3093585\n",
            " 5.44529699 5.48396158 4.80292414 5.51970391 6.20597456 5.22878119\n",
            " 5.75481484 5.65176922 5.63846403 5.95335926 5.60335938 5.40627487\n",
            " 5.94077822 5.24479901 5.85296589 5.25551014 6.24630755 5.55916955\n",
            " 5.50402525 5.75096885 5.60878691 5.1559375  5.25088969 5.61933208\n",
            " 5.52703999 6.16520538 5.90366036 5.39173893 5.47388461 5.49335218\n",
            " 5.81427408 6.05063888 5.69398433 5.80205487 5.41167167 5.90278714\n",
            " 5.2076603 ] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpeUb4ueE0mw",
        "outputId": "a6c62313-2508-42ba-d282-7a110453ac85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#making the pridictions on the testing dataset of Linear regression \n",
        "linear_regression_predictions = linear_regression_classifier.predict(x_test) \n",
        "print(\"The predictions of the linear regressor are: \\n\", linear_regression_predictions,\"\\n\") \n",
        " \n",
        "#Analyzing the performance of the Ridge Regression \n",
        "ridge_regression_score = ridge_regression_classifier.score(x_test, y_test) \n",
        "print(\"Score Value = \",ridge_regression_score, \"\\n\") \n",
        "print(\"Comparing the predictions with the gound-truth: \\n\", \n",
        "np.column_stack((ridge_regression_predictions,y_test)), \"\\n\\n\") \n",
        " \n",
        " \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predictions of the linear regressor are: \n",
            " [5.34680931 5.09871388 5.57099096 5.53512445 5.76976697 5.37636864\n",
            " 5.8645004  5.09862918 5.75972593 5.96349334 6.10407459 5.74641496\n",
            " 5.75227041 5.35513937 5.5104567  6.49204914 5.14966794 5.59158313\n",
            " 6.52401485 5.21847969 5.34788813 5.20718104 5.60308333 5.1873051\n",
            " 5.336025   5.45174488 6.3296073  5.35216888 5.06832602 6.12134123\n",
            " 4.85303339 5.47578024 5.84182996 5.35057032 5.48175719 5.01750133\n",
            " 6.16917837 6.4278236  5.56650991 6.23066541 5.45435092 5.25579819\n",
            " 6.17840215 5.1167346  5.79669578 5.70994374 6.39875661 5.58126655\n",
            " 5.07604075 5.52934704 5.0171063  5.00748235 5.63472119 6.3091227\n",
            " 4.98078092 4.96154087 5.97520013 5.24059552 5.33878153 5.27789213\n",
            " 5.6589185  5.95183617 5.34280574 5.3518964  6.47812679 5.52339339\n",
            " 6.33501105 5.27021103 5.5348005  5.35428663 6.47014863 4.6280101\n",
            " 5.842361   5.88908646 6.17145134 5.2294642  5.40674572 5.96069271\n",
            " 6.0750663  5.41228253 5.36555007 5.25177676 5.46558248 5.7150293\n",
            " 5.690046   6.31750542 5.36006585 5.80737967 6.31294629 5.89621474\n",
            " 6.08846469 5.59552427 5.66241369 5.86459082 5.3036933  5.82331618\n",
            " 5.20450847 5.40577189 5.0258875  5.55729537 5.71228699 5.87772484\n",
            " 5.82695584 5.65818345 6.23189897 6.14375541 5.71671041 5.45317432\n",
            " 6.03357166 5.10706901 6.73005264 5.33363433 6.19868365 4.67278911\n",
            " 5.42770563 5.96214074 6.1250388  5.56146401 5.01626022 5.87417219\n",
            " 6.26822713 5.17896129 5.74035648 5.37012784 5.40487284 5.2676901\n",
            " 6.1878021  5.69071099 5.64553432 6.32762445 5.842361   5.40190727\n",
            " 5.03932566 6.36511283 5.52934704 5.06446144 5.05823887 5.32358412\n",
            " 5.12176406 5.70245323 5.92953065 6.11557875 5.55222292 5.50510338\n",
            " 5.78562026 5.18485926 5.80271623 5.34616889 6.06081941 5.04058711\n",
            " 6.30373088 6.14468013 5.10151521 5.75255828 5.842361   5.16264116\n",
            " 5.25374123 5.93631948 5.96368929 5.90992775 6.34154046 5.79449423\n",
            " 6.09507271 4.94924056 6.15599539 5.74685577 4.57206941 5.27643172\n",
            " 4.96604087 5.02038537 6.19671381 5.1885762  4.95435534 5.50870547\n",
            " 5.61784134 5.81260934 6.0819412  5.43255402 5.46654722 4.99224657\n",
            " 4.7207184  6.39460656 5.58189293 6.47734617 5.19155393 6.31565742\n",
            " 6.03059977 5.9797985  6.73476861 5.50870547 5.41764904 5.99589834\n",
            " 5.64407924 6.57121668 5.79874188 5.76976697 5.69077406 5.50208846\n",
            " 5.50893436 6.14375541 5.41119742 5.55731839 5.59782679 5.01052629\n",
            " 6.66606321 6.13853942 4.88342779 5.7248456  5.71020665 6.1171816\n",
            " 5.91275297 5.07977148 5.29793471 6.59816301 6.39044378 5.79808232\n",
            " 5.2909022  5.17907704 5.13089915 5.3450444  5.09899191 6.27187978\n",
            " 5.58603049 6.04386546 5.0676283  4.75133175 5.29339641 6.4876713\n",
            " 5.57064894 6.08699119 5.50595578 5.06148063 6.3880336  5.98223675\n",
            " 5.91278273 6.14375541 5.35513937 5.690046   4.77040845 5.03096077\n",
            " 5.61978538 4.99831629 5.37031684 6.186832   5.21488604 5.4299241\n",
            " 5.86178465 5.3582501  6.627522   4.91599501 5.79374268 5.64769583\n",
            " 5.27985497 5.45714435 5.03803082 5.13767608 6.25009845 5.87006444\n",
            " 5.71813299 6.74915663 5.75270586 5.307649   5.43255402 6.50503264\n",
            " 5.78603836 5.21946086 5.08121631 4.98051947 5.94943973 6.35793235\n",
            " 5.84299069 5.77944599 4.65626151 5.17734609 5.27481566 5.61562338\n",
            " 5.73196562 5.71002633 6.19999434 5.26664574 6.4731439  4.93493023\n",
            " 5.78760794 5.56704895 5.82888384 5.81569178 4.91180565 6.11557875\n",
            " 5.0068063  5.13408961 6.0706723  6.48800886 5.60193686 5.16638885\n",
            " 4.8974088  6.37454719 5.10100705 6.29912327 6.20010434 6.56704065\n",
            " 5.54147278 5.19282088 6.27185848 5.36671727 5.24564093 5.35098193\n",
            " 5.92789559 5.90151592 6.6149498  6.65206228 5.65548394 5.56988671\n",
            " 5.59195424 5.52315962 5.35057032 5.67692842 5.99051441 5.25636826\n",
            " 6.31002634 5.16761014 5.71924578 6.13491459 5.66384095 5.09405172\n",
            " 4.6391359  5.64625411 4.85607422 6.1572585  4.96154087 6.12134123\n",
            " 6.16255108 6.65206228 5.12768389 5.05530687 5.70523268 4.67086018\n",
            " 5.78749144 6.31553892 5.45150897 5.28080088 6.34303178 6.38928691\n",
            " 6.58858498 5.36080668 5.82572493 4.96762229 6.17145134 5.23298583\n",
            " 5.64646615 5.12049554 5.3597813  5.84070663 5.49206554 4.96604087\n",
            " 5.61833914 5.7140269  5.26598652 5.09307831 5.22178235 5.66857984\n",
            " 5.79803252 5.37898767 6.13475881 5.65548394 5.14606722 5.88496815\n",
            " 5.8388057  6.54338738 5.16338265 5.81077765 5.35140713 5.13089915\n",
            " 6.00109633 5.68426707 5.45800162 6.23066541 5.38384106 6.3649441\n",
            " 5.43182861 5.34939847 5.02567643 6.05593259 6.43248631 5.25028615\n",
            " 6.26317484 5.80637793 6.1224436  5.06178308 5.69683705 5.77800342\n",
            " 5.68338226 5.63663206 4.98231397 4.69279453 6.12531941 5.35513937\n",
            " 6.12881157 5.48175719 5.2688281  6.12412551 5.2641385  5.06827381\n",
            " 5.84916844 5.06968674 5.41739347 5.85180639 6.20411899 6.01532476\n",
            " 6.17328624 5.67692842 5.35342286 6.32428266 6.03156672 5.82127913\n",
            " 5.8938687  5.89518096 5.58232407 6.66111068 5.45781187 6.30651423\n",
            " 5.83112983 5.63979501 6.48051919 5.20373398 5.74195508 5.94746356\n",
            " 5.40761294 5.42156387 5.65818345 5.3222456  6.72177715 5.73332847\n",
            " 4.99912061 5.08437228 6.29945038 5.43725333 5.36363953 5.54851232\n",
            " 4.84393928 6.85428289 5.45006151 6.04262783 6.40021551 5.21680323\n",
            " 5.42682798 5.13768826 5.25548707 5.77751328 5.61279261 5.02570146\n",
            " 6.00443754 5.64561725 5.8379557  5.01077557 5.50489334 6.23079905\n",
            " 6.52691709 5.07271854 5.95589742 5.03961947 4.94001718 5.16609568\n",
            " 5.30898099 5.46312702 5.98332528 5.50244393 5.23189787 5.42618364\n",
            " 6.06937403 6.66316983 6.39974862 5.80818307 5.71168816 5.80818307\n",
            " 5.28356273 5.15157627 6.10472739 5.76976697 6.10407459 5.47384552\n",
            " 6.40860796 5.94889855 5.64994864 5.66606217 6.18682179 5.30053742\n",
            " 5.96706398 6.21982118 5.35513937 5.18301676 6.27929165 5.75255828\n",
            " 4.74859501 6.12347291 5.81527175 4.82561076 5.92953065 5.38388289\n",
            " 4.93507266 5.14378603 4.99475886 5.50956925 5.23922653 5.49206554\n",
            " 5.37041996 5.24668013 5.33456922 5.65548394 6.42337059 6.21939225\n",
            " 5.69764876 6.42337059 5.30804581 6.06165146 4.94670248 6.49133101\n",
            " 5.95910902 5.14637444 5.46558248 5.01973174 5.71444287 5.23462429\n",
            " 5.99079937 6.01875453 6.78403305 6.57672861 4.6533283  5.09024503\n",
            " 5.96189361 6.0369197  5.21946086 6.14634067 5.21847969 5.51298796\n",
            " 5.47740589 4.83171937 5.58390219 4.92166395 5.6001916  6.33382714\n",
            " 5.13974731 5.07618907 5.93491345 5.17277923 5.65316134 5.71108605\n",
            " 4.97506092 5.49802847 5.31817287 5.09982792 5.71547883 5.64223358\n",
            " 4.77040845 4.99371996 5.30703226 5.76260605 5.07258338 5.60592846\n",
            " 6.05182974 5.14775792 4.99778069 5.13408961 5.60204664 5.36985269\n",
            " 5.31995508 5.81958894 5.89777164 5.51330795 5.26179289 6.44044639\n",
            " 6.51394305 5.20270634 6.07943707 5.53299931 5.96957389 5.71794918\n",
            " 5.0211291  5.86094636 5.24004804 5.43719208 5.35527714 4.81677854\n",
            " 5.35378144 6.01448998 5.22969292 6.19356311 6.01882737 4.66464665\n",
            " 5.47632738 4.74987279 5.75116193 5.4061815  5.04210234 5.73562184\n",
            " 5.1132731  6.17162024 6.05484398 5.95966413 5.09917106 6.58623191\n",
            " 4.9712871  4.9194166  5.85524657 6.34704372 5.6117998  5.69551905\n",
            " 6.07072358 4.5600944  5.26685778 5.56559881 5.91209988 6.20550234\n",
            " 4.16235831 6.186832   6.1352124  5.73843606 5.82629184 6.38658402\n",
            " 5.27453948 6.54199121 5.33033515 5.96349334 4.54663774 5.80955307\n",
            " 5.12177947 5.77589318 5.3105118  5.50956925 5.12286175 5.14619404\n",
            " 5.47565764 5.59597928 4.87941254 5.17091517 5.62152051 5.02824265\n",
            " 5.14652303 5.29443836 5.33999097 5.36354946 6.01833744 5.03601128\n",
            " 5.54871482 5.43262922 5.39155411 4.99151368 5.51097858 5.2909022\n",
            " 6.54961797 5.1742347  6.51102217 5.17093303 5.10053575 5.36302454\n",
            " 5.37677692 6.0980855  5.25407045 6.42370317 5.19403886 5.81519604\n",
            " 5.84182996 5.7101874  4.89092723 6.88473773 5.23942895 5.11440227\n",
            " 5.3203648  6.18628312 5.27789213 5.64300964 5.32215508 5.20233768\n",
            " 5.18485926 6.47991831 4.92653271 5.05326146 6.29859922 6.0410272\n",
            " 6.92297772 5.28466287 5.3622644  5.36973516 6.13432947 5.38396802\n",
            " 5.44005268 5.49045263 6.23467231 5.96117337 5.70155135 5.33704099\n",
            " 5.83735552 6.62517972 5.97117718 6.21310925 5.07604075 5.06994706\n",
            " 5.05779287 6.57618589 6.37616906 5.51541236 5.12611179 5.45443802\n",
            " 5.0939583  6.08643742 6.0410272  5.54470377 5.48431855 5.35652514\n",
            " 4.75467302 5.73840159 5.59744034 5.0817073  5.41671596 6.5635415\n",
            " 5.2294642  6.14278404 5.46282148 5.5019648  5.52619712 5.75864677\n",
            " 5.59826814 5.33087464 4.80882409 6.25009845 5.24564093 6.51343521\n",
            " 5.83286534 6.42247367 5.10233844 5.93027843 5.4268058  5.32428107\n",
            " 5.16180723 5.13139556 5.06703957 5.91986766 5.3117109  5.43725301\n",
            " 5.4299241  5.38330382 5.51285627 5.8938687  5.6816807  6.11766345\n",
            " 5.45037326 5.19858553 5.24690524 4.99550483 5.29787977 5.35527714\n",
            " 4.64763904 6.60866775 5.29524691 6.28410424 5.58859298 5.48849458\n",
            " 6.44173555 6.04747767 5.56583329 5.14889574 5.20515768 5.2352124\n",
            " 5.15964655 5.3811677  4.13366117 5.54851232 6.51339664 4.88313171\n",
            " 6.01448998 5.80004261 5.669974   6.07678242 5.65548394 5.21727553\n",
            " 6.11337755 5.0283415  5.81958894 5.12489277 6.75476522 5.55257448\n",
            " 5.34939847 5.84924952 5.61279261 4.97663103 5.03552187 5.58756357\n",
            " 5.37337175 6.49686712 6.16336248 5.23533802 5.4791943  5.37677692\n",
            " 5.83608662 6.2737433  5.65753567 5.96069271 5.36628489 6.04386193\n",
            " 4.97968529] \n",
            "\n",
            "Score Value =  0.30636059937216686 \n",
            "\n",
            "Comparing the predictions with the gound-truth: \n",
            " [[5.402838527270514 '6']\n",
            " [5.341103732948369 '5']\n",
            " [5.517099975667424 '6']\n",
            " ...\n",
            " [5.411671670416208 '5']\n",
            " [5.902787139662173 '6']\n",
            " [5.207660302952416 '5']] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxRupwhOFC68",
        "outputId": "c6f471d9-d754-4924-ce71-2ec742d5e6ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Analyzing the performance of the linear Regression \n",
        "linear_regression_score = linear_regression_classifier.score(x_test, y_test) \n",
        "print(\"Score Value = \",linear_regression_score, \"\\n\") \n",
        "print(\"Comparing the predictions with the gound-truth: \\n\", \n",
        "np.column_stack((linear_regression_predictions,y_test)), \"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Value =  0.35743361337890056 \n",
            "\n",
            "Comparing the predictions with the gound-truth: \n",
            " [[5.346809314611731 '6']\n",
            " [5.098713881576733 '5']\n",
            " [5.57099095651437 '6']\n",
            " ...\n",
            " [5.3662848918636445 '5']\n",
            " [6.043861927217771 '6']\n",
            " [4.979685288881585 '5']] \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1vHTbwCFDwn",
        "outputId": "11ac0b5a-82da-4d6c-dff8-84ea854a9b9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#printing the both the Values of the Effeciency  \n",
        "print(\"Score Value of Ridge = \",ridge_regression_score, \"\\n\") \n",
        "print(\"Score Value of Linear = \",linear_regression_score, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Value of Ridge =  0.30636059937216686 \n",
            "\n",
            "Score Value of Linear =  0.35743361337890056 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}